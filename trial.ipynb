{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1a871f-d98d-409c-bdcc-0cfd7a19cc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "{GradientBoostingClassifier(random_state=42): [['acc', 0.9835], ['f1', np.float64(0.6796116504854369)]], RandomForestClassifier(random_state=42): [['acc', 0.984], ['f1', np.float64(0.6862745098039216)]], AdaBoostClassifier(random_state=42): [['acc', 0.977], ['f1', np.float64(0.5660377358490566)]], DecisionTreeClassifier(random_state=42): [['acc', 0.981], ['f1', np.float64(0.7076923076923077)]], LogisticRegression(random_state=42): [['acc', 0.974], ['f1', np.float64(0.4090909090909091)]], SVC(random_state=42): [['acc', 0.9695], ['f1', np.float64(0.0)]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b2ec448-fc9c-46a2-9406-bf0184c00b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7076923076923077\n"
     ]
    }
   ],
   "source": [
    "    l  = 0\n",
    "\n",
    "for i,v in d.items():\n",
    "    if l<v[1][1]:\n",
    "        l = v[1][1]\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26951fd2-48b5-4cb2-b5e2-3a606d3fd8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "{GradientBoostingClassifier(random_state=42): [['acc', 0.963777490297542], ['f1', np.float64(0.9643221202854231)]], RandomForestClassifier(random_state=42): [['acc', 0.9844760672703752], ['f1', np.float64(0.9845599588265569)]], AdaBoostClassifier(random_state=42): [['acc', 0.9467011642949548], ['f1', np.float64(0.9474221541602859)]], DecisionTreeClassifier(random_state=42): [['acc', 0.9728331177231565], ['f1', np.float64(0.9729032258064516)]], LogisticRegression(random_state=42): [['acc', 0.8369987063389392], ['f1', np.float64(0.8376288659793815)]], SVC(random_state=42): [['acc', 0.8408796895213454], ['f1', np.float64(0.8455162019593067)]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfa61916-1ee9-4df3-9c86-dda015755ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from xgboost  import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4677265-f0f2-4a8e-a105-08f74ba973db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "classification report of GradientBoostingClassifier(random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1934\n",
      "           1       0.95      0.98      0.96      1931\n",
      "\n",
      "    accuracy                           0.96      3865\n",
      "   macro avg       0.96      0.96      0.96      3865\n",
      "weighted avg       0.96      0.96      0.96      3865\n",
      "\n",
      "**************************************************\n",
      "classification report of RandomForestClassifier(random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1934\n",
      "           1       0.98      0.99      0.98      1931\n",
      "\n",
      "    accuracy                           0.98      3865\n",
      "   macro avg       0.98      0.98      0.98      3865\n",
      "weighted avg       0.98      0.98      0.98      3865\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshan Salunke\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "classification report of AdaBoostClassifier(random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      1934\n",
      "           1       0.94      0.94      0.94      1931\n",
      "\n",
      "    accuracy                           0.94      3865\n",
      "   macro avg       0.94      0.94      0.94      3865\n",
      "weighted avg       0.94      0.94      0.94      3865\n",
      "\n",
      "**************************************************\n",
      "classification report of DecisionTreeClassifier(random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1934\n",
      "           1       0.97      0.98      0.97      1931\n",
      "\n",
      "    accuracy                           0.97      3865\n",
      "   macro avg       0.97      0.97      0.97      3865\n",
      "weighted avg       0.97      0.97      0.97      3865\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshan Salunke\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "classification report of LogisticRegression(random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.84      1934\n",
      "           1       0.83      0.84      0.84      1931\n",
      "\n",
      "    accuracy                           0.84      3865\n",
      "   macro avg       0.84      0.84      0.84      3865\n",
      "weighted avg       0.84      0.84      0.84      3865\n",
      "\n",
      "**************************************************\n",
      "classification report of SVC(random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.81      0.84      1934\n",
      "           1       0.82      0.87      0.85      1931\n",
      "\n",
      "    accuracy                           0.84      3865\n",
      "   macro avg       0.84      0.84      0.84      3865\n",
      "weighted avg       0.84      0.84      0.84      3865\n",
      "\n",
      "**************************************************\n",
      "classification report of XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      1934\n",
      "           1       0.98      0.99      0.99      1931\n",
      "\n",
      "    accuracy                           0.99      3865\n",
      "   macro avg       0.99      0.99      0.99      3865\n",
      "weighted avg       0.99      0.99      0.99      3865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "l = [GradientBoostingClassifier(random_state=42), RandomForestClassifier(random_state=42),\n",
    "     AdaBoostClassifier(random_state=42), DecisionTreeClassifier(random_state=42),\n",
    "     LogisticRegression(random_state=42), SVC(random_state=42), XGBClassifier(random_state=42)]\n",
    "\n",
    "ai4i_2020_predictive_maintenance_dataset = fetch_ucirepo(id=601) \n",
    "X = ai4i_2020_predictive_maintenance_dataset.data.features \n",
    "y = ai4i_2020_predictive_maintenance_dataset.data.targets \n",
    "y = y['Machine failure']\n",
    "\n",
    "one = OneHotEncoder()\n",
    "dfone = pd.DataFrame(one.fit_transform(pd.DataFrame(X['Type'])).toarray(),columns=['H','L','M'])\n",
    "df = pd.concat([X,dfone],axis=1)\n",
    "df.drop('Type',axis=1,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "x,y = SMOTE().fit_resample(df,y)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=.2, random_state=42)\n",
    "\n",
    "\n",
    "d = {}\n",
    "\n",
    "def model_building(model_list):\n",
    "    for i in model_list:\n",
    "        i.fit(x_train, y_train)\n",
    "        pred = i.predict(x_test)\n",
    "        print('*'*50)\n",
    "        print(f'classification report of {i}')\n",
    "        print(classification_report(y_test, pred))\n",
    "        \n",
    "        if i not in d:\n",
    "        \n",
    "            d[i] = [['acc',accuracy_score(pred, y_test)],['f1',f1_score(y_test, pred)]]\n",
    "                        \n",
    "    return d\n",
    "\n",
    "        \n",
    "d = model_building(l)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2a73e321-1e19-4109-9939-e54532d508b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "classification report of GradientBoostingClassifier(random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1939\n",
      "           1       0.83      0.57      0.68        61\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.91      0.79      0.84      2000\n",
      "weighted avg       0.98      0.98      0.98      2000\n",
      "\n",
      "**************************************************\n",
      "classification report of RandomForestClassifier(random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1939\n",
      "           1       0.85      0.57      0.69        61\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.92      0.79      0.84      2000\n",
      "weighted avg       0.98      0.98      0.98      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshan Salunke\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "classification report of AdaBoostClassifier(random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      1939\n",
      "           1       0.67      0.49      0.57        61\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.83      0.74      0.78      2000\n",
      "weighted avg       0.97      0.98      0.98      2000\n",
      "\n",
      "**************************************************\n",
      "classification report of DecisionTreeClassifier(random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1939\n",
      "           1       0.67      0.75      0.71        61\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.83      0.87      0.85      2000\n",
      "weighted avg       0.98      0.98      0.98      2000\n",
      "\n",
      "**************************************************\n",
      "classification report of LogisticRegression(random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1939\n",
      "           1       0.67      0.30      0.41        61\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.82      0.65      0.70      2000\n",
      "weighted avg       0.97      0.97      0.97      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshan Salunke\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "classification report of SVC(random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1939\n",
      "           1       0.00      0.00      0.00        61\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.48      0.50      0.49      2000\n",
      "weighted avg       0.94      0.97      0.95      2000\n",
      "\n",
      "**************************************************\n",
      "classification report of XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1939\n",
      "           1       0.80      0.66      0.72        61\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.89      0.83      0.86      2000\n",
      "weighted avg       0.98      0.98      0.98      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roshan Salunke\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Roshan Salunke\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Roshan Salunke\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "l = [GradientBoostingClassifier(random_state=42), RandomForestClassifier(random_state=42),\n",
    "     AdaBoostClassifier(random_state=42), DecisionTreeClassifier(random_state=42),\n",
    "     LogisticRegression(random_state=42), SVC(random_state=42),XGBClassifier(random_state=42)]\n",
    "\n",
    "ai4i_2020_predictive_maintenance_dataset = fetch_ucirepo(id=601) \n",
    "X = ai4i_2020_predictive_maintenance_dataset.data.features \n",
    "y = ai4i_2020_predictive_maintenance_dataset.data.targets \n",
    "y = y['Machine failure']\n",
    "\n",
    "one = OneHotEncoder()\n",
    "dfone = pd.DataFrame(one.fit_transform(pd.DataFrame(X['Type'])).toarray(),columns=['H','L','M'])\n",
    "df = pd.concat([X,dfone],axis=1)\n",
    "df.drop('Type',axis=1,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df,y, test_size=.2, random_state=42)\n",
    "\n",
    "\n",
    "d = {}\n",
    "\n",
    "def model_building(model_list):\n",
    "    for i in model_list:\n",
    "        i.fit(x_train, y_train)\n",
    "        pred = i.predict(x_test)\n",
    "        print('*'*50)\n",
    "        print(f'classification report of {i}')\n",
    "        print(classification_report(y_test, pred))\n",
    "        \n",
    "        if i not in d:\n",
    "        \n",
    "            d[i] = [['acc',accuracy_score(pred, y_test)],['f1',f1_score(y_test, pred)]]\n",
    "                        \n",
    "    return d\n",
    "\n",
    "        \n",
    "d = model_building(l)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3172ead9-65b6-4354-97b2-9d90406f9413",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "l = [GradientBoostingClassifier(random_state=42), RandomForestClassifier(random_state=42),\n",
    "     AdaBoostClassifier(random_state=42), DecisionTreeClassifier(random_state=42),\n",
    "     LogisticRegression(random_state=42), SVC(random_state=42),XGBClassifier(random_state=42)]\n",
    "\n",
    "ai4i_2020_predictive_maintenance_dataset = fetch_ucirepo(id=601) \n",
    "X = ai4i_2020_predictive_maintenance_dataset.data.features \n",
    "y = ai4i_2020_predictive_maintenance_dataset.data.targets \n",
    "y = y['Machine failure']\n",
    "\n",
    "one = OneHotEncoder()\n",
    "dfone = pd.DataFrame(one.fit_transform(pd.DataFrame(X['Type'])).toarray(),columns=['H','L','M'])\n",
    "df = pd.concat([X,dfone],axis=1)\n",
    "df.drop('Type',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f9d9e4a-3e5b-49cf-9dc7-5459ec311ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Machine failure\n",
       "0    9661\n",
       "1     339\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e997fb8-8574-4a84-ac7e-1f00b4235c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2637e567-83a9-41b3-84c8-c7c476739729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.39"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(df[df['y']==1])/len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce8b565d-4078-4b20-9441-9cebae94506c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.508953524479867"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(339/9661)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f03ea01-9846-4646-9250-b2e93d9af400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Machine failure\n",
       "0    9661\n",
       "1     339\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ef6d858-a3a8-4a64-8998-137bf6c84a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.39"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "339/(339+9661)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc714d00-e3c6-4d12-aee3-ec9dd679a35d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
